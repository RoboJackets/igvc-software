<!-- vision.launch -->
<!-- This file launches a vision node that uses a CNN to detect lines. -->

<launch>


    <node name = "segmented_camera_info_publisher" pkg = "igvc_platform" type = "uhhhh" output = "uhhh">
        <rosparam param="camera_names">["/cam/center", "/cam/left", "/cam/right"]</rosparam>
        <rosparam param="semantic_info_topic_prefix">["/cam/center", "/cam/left", "/cam/right"]</rosparam>
        <rosparam param="semantic_info_topic_suffix">["", "", ""]</rosparam>

        <param name="image_info_base_topic" value="/raw/image" />

        <param name="output_width" value="600" />
        <param name="output_height" value="480" />
    </node>
    
    <node name="cnn" pkg="igvc_perception" type="cnn.py" output="screen required="true" />

    <rosparam param="camera_names">["usb_cam_center", "usb_cam_left", "usb_cam_right"]</rosparam>

    <!-- These sizes must match the model input dimensions. -->
    <param name="image_resize_width" value="400" />
    <param name="image_resize_height" value="400" />

    <param name="model_path" value="$(find igvc_sandbox)/models/YS/IGVCModel_135.pt" />

    <!-- Use cpu instead of GPU (will run very slowly). -->
    <param name="force_cpu" value="false" />

    <!-- Threshold to determine if a network prediction is a line (values between 0 and 1) -->
    <param name="line_thresh" value="0.95" />

    <param name="output_segmentation_topic" value="/semantic_segmentation" />

    <!-- Use a pre-existic segmented image such as an output segmentation from a different node.
         If true, the "segmented_image_topics" rosparam must be set with one topic for each camera -->
    <param name="use_preexisting_segmentation" value="false"/>
    <rosparam param="segmented_image_topics">["/center_cam/detected_lines", "/left_cam/detected_lines", "/right_cam/detected_lines"]</rosparam>

</launch>
